{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6350c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "base_dir = './output'\n",
    "\n",
    "images_dir = './images'\n",
    "\n",
    "class_names = ['Car', 'Pedestrian', 'Cyclist']\n",
    "\n",
    "headings = ['model', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'memory_usage_mean_mb', 'memory_usage_std_mb', 'gpu_memory_usage_mean_mb', 'gpu_memory_usage_std_mb', 'per_object_memory_usage_mean_mb', 'per_object_memory_usage_std_mb', 'per_object_gpu_memory_usage_mean_mb', 'per_object_gpu_memory_usage_std_mb', 'inference_time_mean_sec', 'inference_time_std_sec', 'per_object_inference_time_mean_sec', 'per_object_inference_time_std_sec', 'num_samples', 'num_classes', 'model_memory_footprint_mb', 'model_gpu_memory_footprint_mb', 'car_precision', 'car_recall', 'car_f1', 'pedestrian_precision', 'pedestrian_recall', 'pedestrian_f1', 'cyclist_precision', 'cyclist_recall', 'cyclist_f1']\n",
    "\n",
    "headings_labels = ['Model', 'Accuracy', 'Precision (Macro)', 'Recall (Macro)', 'F1 Score (Macro)', 'Precision (Weighted)', 'Recall (Weighted)', 'F1 Score (Weighted)', 'Memory Usage (Mean, MB)', 'Memory Usage (Std, MB)', 'GPU Memory Usage (Mean, MB)', 'GPU Memory Usage (Std, MB)', 'Per Object Memory Usage (Mean, MB)', 'Per Object Memory Usage (Std, MB)', 'Per Object GPU Memory Usage (Mean, MB)', 'Per Object GPU Memory Usage (Std, MB)', 'Inference Time (Mean, Sec)', 'Inference Time (Std, Sec)', 'Per Object Inference Time (Mean, Sec)', 'Per Object Inference Time (Std, Sec)', 'Number of Samples', 'Number of Classes', 'Model Memory Footprint (MB)', 'Model GPU memory footprint (MB)', 'Car Precision', 'Car Recall', 'Car F1', 'Pedestrian Precision', 'Pedestrian Recall', 'Pedestrian F1', 'Cyclist Precision', 'Cyclist Recall', 'Cyclist F1']\n",
    "\n",
    "assert len(headings) == len(headings_labels), \"Headings and labels must have the same length\"\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48554ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(images_dir):\n",
    "\n",
    "\tos.system(\"mkdir -p \" + images_dir)\n",
    "\n",
    "else :\n",
    "\n",
    "\tfiles = os.listdir(images_dir)\n",
    "\n",
    "\tfor file in files:\n",
    "\n",
    "\t\tif 'confusion_matrix' not in file:\n",
    "\n",
    "\t\t\tos.remove(os.path.join(images_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335000b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet_data = pd.read_csv(os.path.join(base_dir, 'pointnet_real_classification_results.csv'))\n",
    "pointnetpp_data = pd.read_csv(os.path.join(base_dir, 'pointnetpp_real_classification_results.csv'))\n",
    "pointpillars_data = pd.read_csv(os.path.join(base_dir, 'pointpillar_classification_results.csv'))\n",
    "pointrcnn_data = pd.read_csv(os.path.join(base_dir, 'pointrcnn_classification_results.csv'))\n",
    "\n",
    "pointnet_data['model'] = 'PointNet'\n",
    "pointnetpp_data['model'] = 'PointNet++'\n",
    "pointpillars_data['model'] = 'PointPillars'\n",
    "pointrcnn_data['model'] = 'PointRCNN'\n",
    "\n",
    "data = pd.concat([pointnet_data, pointnetpp_data, pointpillars_data, pointrcnn_data], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "\n",
    "metrics = ['model', 'per_object_memory_usage_mean_mb', 'per_object_gpu_memory_usage_mean_mb', 'model_memory_footprint_mb', 'model_gpu_memory_footprint_mb']\n",
    "metrics_data = data_copy[metrics]\n",
    "metrics_data.columns = [headings_labels[headings.index(col)] for col in metrics]\n",
    "latex_table = metrics_data.to_latex(index=False, float_format=\"%.3f\", escape=False)\n",
    "print(latex_table)\n",
    "\n",
    "metrics = ['model', 'per_object_inference_time_mean_sec', 'inference_time_mean_sec']\n",
    "metrics_data = data_copy[metrics]\n",
    "metrics_data.columns = [headings_labels[headings.index(col)] for col in metrics]\n",
    "latex_table = metrics_data.to_latex(index=False, float_format=\"%.3f\", escape=False)\n",
    "print(latex_table)\n",
    "\n",
    "metrics = ['model', 'accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "metrics_data = data_copy[metrics]\n",
    "metrics_data.columns = [headings_labels[headings.index(col)] for col in metrics]\n",
    "latex_table = metrics_data.to_latex(index=False, float_format=\"%.3f\", escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = plt.bar(data['model'], data['accuracy'], color=colors[:len(data['model'])])\n",
    "\n",
    "for bar in bars:\n",
    "\n",
    "\theight = bar.get_height()\n",
    "\n",
    "\tax.text(\n",
    "\t\tbar.get_x() + bar.get_width() / 2,\n",
    "\t\theight - 0.1,\n",
    "\t\tf'{height:.4f}',\n",
    "\t\tha='center',\n",
    "\t\tva='bottom'\n",
    "\t)\n",
    "\n",
    "ax.axhline(y=1.0, color='black', linestyle='--', alpha=0.7, label='Perfect score')\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(images_dir, 'accuracy.png'))\n",
    "plt.savefig(os.path.join(images_dir, 'accuracy.pdf'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', 'f1_macro', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "n_metrics = len(metrics)\n",
    "bar_width = 0.1\n",
    "bar_spacing = 0.05\n",
    "group_width = n_metrics * (bar_width + bar_spacing)\n",
    "\n",
    "models = data['model'].unique()\n",
    "n_models = len(models)\n",
    "\n",
    "x = np.arange(n_models)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "\n",
    "\tmetric_values = [data[data['model'] == model][metric].values[0] for model in models]\n",
    "\n",
    "\tbars = ax.bar(x + i * (bar_width + bar_spacing), metric_values, width=bar_width, label=headings_labels[i + 1])\n",
    "\n",
    "\tfor j, bar in enumerate(bars):\n",
    "\n",
    "\t\theight = bar.get_height()\n",
    "\n",
    "\t\tax.text(\n",
    "\t\t\tbar.get_x() + bar.get_width() / 2,\n",
    "\t\t\theight - 0.1,\n",
    "\t\t\tf'{height:.4f}',\n",
    "\t\t\tha='center',\n",
    "\t\t\tva='bottom',\n",
    "\t\t\trotation=90,\n",
    "\t\t)\n",
    "\n",
    "ax.axhline(y=1.0, color='black', linestyle='--', alpha=0.7, label='Perfect score')\n",
    "\n",
    "plt.title('Model performance metrics')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(x + (n_metrics - 1) * (bar_width + bar_spacing) / 2, models, rotation=45)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1.0129), title='Metrics')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(images_dir, 'model_performance_metrics.png'))\n",
    "plt.savefig(os.path.join(images_dir, 'model_performance_metrics.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = plt.bar(data['model'], data['per_object_memory_usage_mean_mb'], color=colors[:len(data['model'])])\n",
    "\n",
    "for bar in bars:\n",
    "\n",
    "\theight = bar.get_height()\n",
    "\n",
    "\tax.text(\n",
    "\t\tbar.get_x() + bar.get_width() / 2,\n",
    "\t\theight,\n",
    "\t\tf'{height:.2f}',\n",
    "\t\tha='center',\n",
    "\t\tva='bottom'\n",
    "\t)\n",
    "\n",
    "plt.title('Model memory usage per object')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Memory usage (MB)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(images_dir, 'memory_usage.png'))\n",
    "plt.savefig(os.path.join(images_dir, 'memory_usage.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bars = plt.bar(data['model'], data['inference_time_mean_sec'], color=colors[:len(data['model'])])\n",
    "\n",
    "for bar in bars:\n",
    "\n",
    "\theight = bar.get_height()\n",
    "\n",
    "\tax.text(\n",
    "\t\tbar.get_x() + bar.get_width() / 2,\n",
    "\t\theight,\n",
    "\t\tf'{height:.3f}',\n",
    "\t\tha='center',\n",
    "\t\tva='bottom',\n",
    "\t\tfontsize=8\n",
    "\t)\n",
    "\n",
    "plt.title('Model inference time per object', fontsize=16)\n",
    "plt.xlabel('Model', fontsize=14)\n",
    "plt.ylabel('Inference time (seconds)', fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(images_dir, 'inference_time.png'))\n",
    "plt.savefig(os.path.join(images_dir, 'inference_time.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ae788",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bars = plt.bar(data['model'], data['model_memory_footprint_mb'], color=colors[:len(data['model'])])\n",
    "\n",
    "for bar in bars:\n",
    "\n",
    "\theight = bar.get_height()\n",
    "\n",
    "\tax.text(\n",
    "\t\tbar.get_x() + bar.get_width() / 2,\n",
    "\t\theight,\n",
    "\t\tf'{height:.3f}',\n",
    "\t\tha='center',\n",
    "\t\tva='bottom'\n",
    "\t)\n",
    "\n",
    "plt.title('Model memory usage')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Memory usage (MB)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(images_dir, 'model_memory_usage.png'))\n",
    "plt.savefig(os.path.join(images_dir, 'model_memory_usage.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
